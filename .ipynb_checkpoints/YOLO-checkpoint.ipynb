{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 771,
     "status": "ok",
     "timestamp": 1736040071012,
     "user": {
      "displayName": "Công Thành Nguyễn",
      "userId": "18021098019939229396"
     },
     "user_tz": -420
    },
    "id": "qKrO7bwV7gvA",
    "outputId": "082616bd-4e69-4a04-d082-70796a72fe81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đây là dự án thử nghiệm YOLO\n"
     ]
    }
   ],
   "source": [
    "print('Đây là dự án thử nghiệm YOLO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HUhzUgPS7-Bw"
   },
   "source": [
    "Dự án là một phương án cho đồ án tốt nghiệp cũng như tìm hiểu cách thức và khả năng hoạt động của google colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AYUYon-h8fcN"
   },
   "source": [
    "\n",
    "\n",
    "1.   Chuẩn bị thư viện\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "Oz17qG3a79Z9",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# pip install ultralytics\n",
    "# pip install roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 6353,
     "status": "ok",
     "timestamp": 1736040097835,
     "user": {
      "displayName": "Công Thành Nguyễn",
      "userId": "18021098019939229396"
     },
     "user_tz": -420
    },
    "id": "qdwOjJcaTCbo",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "5912223b-92ec-45d2-c362-cd90247f2cc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.57-py3-none-any.whl.metadata (35 kB)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.8.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Downloading ultralytics_thop-2.0.13-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.12.14)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Downloading ultralytics-8.3.57-py3-none-any.whl (905 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m905.3/905.3 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ultralytics_thop-2.0.13-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: ultralytics-thop, ultralytics\n",
      "Successfully installed ultralytics-8.3.57 ultralytics-thop-2.0.13\n"
     ]
    }
   ],
   "source": [
    "pip install ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LO1FqHFxJK8r"
   },
   "source": [
    "\n",
    "\n",
    "2.   Kết nối với Google Drive (chưa cần thiết)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 21105,
     "status": "ok",
     "timestamp": 1736040125360,
     "user": {
      "displayName": "Công Thành Nguyễn",
      "userId": "18021098019939229396"
     },
     "user_tz": -420
    },
    "id": "evq2WQtpAvr7",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "a9eba151-3729-4164-d085-a04114a68f86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "'10-Nguyễn Công Thành.mkv'\t\t\t   HTML\n",
      "'2402_Buoi03_ThanhNC(Tren_Lop).sql'\t\t   Java\n",
      " Android2.drawio\t\t\t\t   K16_Testing11_nhom10\n",
      " Android.drawio\t\t\t\t\t  'K16_Testing11_nhom10 (1)'\n",
      " ArtStoreProject.rar\t\t\t\t  'Kiem thu'\n",
      " Bài-tập-thuyết-trình-về-khu-vực.pptx\t\t  'LeagueClient Logs.rar'\n",
      " BBKH_TruongCongManh.docx\t\t\t   Maven\n",
      " BCKH_TruongCongManh.docx\t\t\t   NgoaiNgu\n",
      "'Biểu đồ ca sử dụng.gdoc'\t\t\t  'Nguyễn Công Thành.pdf'\n",
      "'BTL Học máy'\t\t\t\t\t  'Nhóm 14 TTCSN'\n",
      " BTL_N1_HocMay_final.docx\t\t\t   Presentation4.pptx\n",
      "'Buổi 1 - Giới thiệu HP gửi SV.pptx'\t\t  'Professional statement exemplar.gdoc'\n",
      "'Chương 1_2 MỘT SỐ GỢI Ý ĐỂ HỌC TỐT (1).gslides'  'Professional statement outline.gdoc'\n",
      "'Chương 1_2 MỘT SỐ GỢI Ý ĐỂ HỌC TỐT (2).gslides'   Python\n",
      "'Chương 1_2 MỘT SỐ GỢI Ý ĐỂ HỌC TỐT.gslides'\t   Python.drawio\n",
      "'Chương 2 Cơ bản về MT - CNTT (1).gslides'\t   SQL\n",
      "'Chương 2 Cơ bản về MT - CNTT (2).gslides'\t  'Tên các use case.gdoc'\n",
      "'Chương 2 Cơ bản về MT - CNTT.gslides'\t\t   TestScore.png\n",
      " Classroom\t\t\t\t\t   TTDN.drawio\n",
      "'Colab Notebooks'\t\t\t\t   Untitled-2.ai\n",
      " Cookingisfun.drawio\t\t\t\t  'Untitled design.png'\n",
      "'CV-Nguyễn Công Thành.pdf'\t\t\t  'Untitled Diagram (1).drawio'\n",
      "'Đặc tả các use case.gdoc'\t\t\t  'Untitled Diagram (2).drawio'\n",
      "'Đặc tả user .gdoc'\t\t\t\t  'Untitled Diagram (3).drawio'\n",
      "'EnglishScoreCertificate (1).png'\t\t  'Untitled Diagram (4).drawio'\n",
      " EnglishScoreCertificate.png\t\t\t  'Untitled Diagram (5).drawio'\n",
      " EnglishScore.png\t\t\t\t  'Untitled Diagram.drawio'\n",
      "'[HAUI] CV Fresher-Nguyễn Công Thành.pdf.pdf'\t   UseCase_PythonNC.drawio\n",
      "'[HAUI] CV Intern AI-Nguyễn Công Thành.pdf'\t  'Ý tưởng riêng'\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "!ls \"/content/drive/My Drive\"\n",
    "\n",
    "# !fusermount -u /content/drive\n",
    "# !rm -rf /content/drive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jH2UJ9L-JWSM"
   },
   "source": [
    "\n",
    "3.   Sử dụng mô hình Yolo(yolov8n) có sẵn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 27774,
     "status": "ok",
     "timestamp": 1735993068400,
     "user": {
      "displayName": "Công Thành Nguyễn",
      "userId": "18021098019939229396"
     },
     "user_tz": -420
    },
    "id": "9ah4R1cm9FCT",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "2110a530-f402-4370-8552-b3d5c7b15923"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "WARNING ⚠️ inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "video 1/1 (frame 1/49) /content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4: 384x640 1 goalkeeper, 23 players, 1 referee, 401.6ms\n",
      "video 1/1 (frame 2/49) /content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4: 384x640 1 goalkeeper, 22 players, 1 referee, 331.9ms\n",
      "video 1/1 (frame 3/49) /content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4: 384x640 1 goalkeeper, 24 players, 1 referee, 360.4ms\n",
      "video 1/1 (frame 4/49) /content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4: 384x640 1 goalkeeper, 22 players, 1 referee, 371.6ms\n",
      "video 1/1 (frame 5/49) /content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4: 384x640 1 goalkeeper, 21 players, 1 referee, 360.0ms\n",
      "video 1/1 (frame 6/49) /content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4: 384x640 1 goalkeeper, 21 players, 1 referee, 342.8ms\n",
      "video 1/1 (frame 7/49) /content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4: 384x640 1 goalkeeper, 23 players, 1 referee, 326.4ms\n",
      "video 1/1 (frame 8/49) /content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4: 384x640 1 goalkeeper, 25 players, 1 referee, 373.3ms\n",
      "video 1/1 (frame 9/49) /content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4: 384x640 1 goalkeeper, 23 players, 1 referee, 368.9ms\n",
      "video 1/1 (frame 10/49) /content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4: 384x640 2 goalkeepers, 20 players, 1 referee, 363.9ms\n",
      "video 1/1 (frame 11/49) /content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4: 384x640 1 goalkeeper, 22 players, 1 referee, 356.0ms\n",
      "video 1/1 (frame 12/49) /content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4: 384x640 1 goalkeeper, 23 players, 1 referee, 498.9ms\n",
      "video 1/1 (frame 13/49) /content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4: 384x640 1 goalkeeper, 20 players, 1 referee, 535.3ms\n",
      "video 1/1 (frame 14/49) /content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4: 384x640 1 goalkeeper, 20 players, 1 referee, 526.3ms\n",
      "video 1/1 (frame 15/49) /content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4: 384x640 1 goalkeeper, 19 players, 1 referee, 538.4ms\n",
      "video 1/1 (frame 16/49) /content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4: 384x640 1 goalkeeper, 21 players, 1 referee, 504.9ms\n",
      "video 1/1 (frame 17/49) /content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4: 384x640 1 goalkeeper, 20 players, 1 referee, 515.5ms\n",
      "video 1/1 (frame 18/49) /content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4: 384x640 1 goalkeeper, 21 players, 1 referee, 411.4ms\n",
      "video 1/1 (frame 19/49) /content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4: 384x640 1 goalkeeper, 22 players, 1 referee, 338.8ms\n",
      "video 1/1 (frame 20/49) /content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4: 384x640 1 goalkeeper, 21 players, 1 referee, 349.0ms\n",
      "video 1/1 (frame 21/49) /content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4: 384x640 1 goalkeeper, 21 players, 1 referee, 373.5ms\n",
      "video 1/1 (frame 22/49) /content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4: 384x640 1 goalkeeper, 19 players, 349.6ms\n",
      "video 1/1 (frame 23/49) /content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4: 384x640 1 goalkeeper, 18 players, 1 referee, 358.5ms\n",
      "video 1/1 (frame 24/49) /content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4: 384x640 1 goalkeeper, 19 players, 2 referees, 361.4ms\n",
      "video 1/1 (frame 25/49) /content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4: 384x640 1 goalkeeper, 20 players, 1 referee, 349.7ms\n",
      "video 1/1 (frame 26/49) /content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4: 384x640 2 goalkeepers, 21 players, 2 referees, 369.0ms\n",
      "video 1/1 (frame 27/49) /content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4: 384x640 1 goalkeeper, 19 players, 1 referee, 361.6ms\n",
      "video 1/1 (frame 28/49) /content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4: 384x640 1 goalkeeper, 22 players, 1 referee, 366.2ms\n",
      "video 1/1 (frame 29/49) /content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4: 384x640 1 goalkeeper, 21 players, 1 referee, 328.7ms\n",
      "video 1/1 (frame 30/49) /content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4: 384x640 1 goalkeeper, 22 players, 1 referee, 312.1ms\n",
      "video 1/1 (frame 31/49) /content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4: 384x640 1 goalkeeper, 21 players, 1 referee, 341.5ms\n",
      "video 1/1 (frame 32/49) /content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4: 384x640 1 goalkeeper, 22 players, 1 referee, 353.0ms\n",
      "video 1/1 (frame 33/49) /content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4: 384x640 27 players, 1 referee, 365.9ms\n",
      "video 1/1 (frame 34/49) /content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4: 384x640 21 players, 1 referee, 351.1ms\n",
      "video 1/1 (frame 35/49) /content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4: 384x640 20 players, 1 referee, 317.1ms\n",
      "video 1/1 (frame 36/49) /content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4: 384x640 1 goalkeeper, 20 players, 2 referees, 337.5ms\n",
      "video 1/1 (frame 37/49) /content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4: 384x640 1 goalkeeper, 19 players, 1 referee, 359.3ms\n",
      "video 1/1 (frame 38/49) /content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4: 384x640 1 goalkeeper, 20 players, 1 referee, 380.1ms\n",
      "video 1/1 (frame 39/49) /content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4: 384x640 1 goalkeeper, 24 players, 1 referee, 350.3ms\n",
      "video 1/1 (frame 40/49) /content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4: 384x640 1 goalkeeper, 25 players, 1 referee, 320.6ms\n",
      "video 1/1 (frame 41/49) /content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4: 384x640 1 goalkeeper, 21 players, 1 referee, 336.8ms\n",
      "video 1/1 (frame 42/49) /content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4: 384x640 1 goalkeeper, 21 players, 1 referee, 393.6ms\n",
      "video 1/1 (frame 43/49) /content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4: 384x640 1 goalkeeper, 20 players, 1 referee, 512.5ms\n",
      "video 1/1 (frame 44/49) /content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4: 384x640 1 goalkeeper, 19 players, 1 referee, 532.5ms\n",
      "video 1/1 (frame 45/49) /content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4: 384x640 1 goalkeeper, 18 players, 1 referee, 536.7ms\n",
      "video 1/1 (frame 46/49) /content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4: 384x640 1 goalkeeper, 18 players, 1 referee, 505.5ms\n",
      "video 1/1 (frame 47/49) /content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4: 384x640 1 goalkeeper, 18 players, 1 referee, 500.7ms\n",
      "video 1/1 (frame 48/49) /content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4: 384x640 1 goalkeeper, 19 players, 1 referee, 569.4ms\n",
      "video 1/1 (frame 49/49) /content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4: 384x640 1 goalkeeper, 18 players, 1 referee, 412.6ms\n",
      "Speed: 5.8ms preprocess, 397.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'ball', 1: 'goalkeeper', 2: 'player', 3: 'referee'}\n",
      "obb: None\n",
      "orig_img: array([[[ 26,  27,  37],\n",
      "        [ 26,  27,  37],\n",
      "        [ 25,  26,  36],\n",
      "        ...,\n",
      "        [ 99,  99,  83],\n",
      "        [ 87,  87,  71],\n",
      "        [ 65,  65,  49]],\n",
      "\n",
      "       [[ 20,  21,  31],\n",
      "        [ 21,  22,  32],\n",
      "        [ 21,  22,  32],\n",
      "        ...,\n",
      "        [ 84,  84,  68],\n",
      "        [ 71,  71,  55],\n",
      "        [ 58,  58,  42]],\n",
      "\n",
      "       [[ 21,  22,  32],\n",
      "        [ 24,  25,  35],\n",
      "        [ 24,  25,  35],\n",
      "        ...,\n",
      "        [ 70,  69,  56],\n",
      "        [ 61,  60,  47],\n",
      "        [ 56,  55,  42]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 38,  57,  43],\n",
      "        [ 37,  56,  42],\n",
      "        [ 34,  53,  39],\n",
      "        ...,\n",
      "        [ 66, 118,  97],\n",
      "        [ 66, 118,  97],\n",
      "        [ 66, 118,  97]],\n",
      "\n",
      "       [[ 38,  57,  43],\n",
      "        [ 37,  56,  42],\n",
      "        [ 34,  53,  39],\n",
      "        ...,\n",
      "        [ 66, 118,  97],\n",
      "        [ 66, 118,  97],\n",
      "        [ 64, 116,  95]],\n",
      "\n",
      "       [[ 38,  57,  43],\n",
      "        [ 37,  56,  42],\n",
      "        [ 34,  53,  39],\n",
      "        ...,\n",
      "        [ 66, 118,  97],\n",
      "        [ 66, 118,  97],\n",
      "        [ 64, 116,  95]]], dtype=uint8)\n",
      "orig_shape: (1080, 1920)\n",
      "path: '/content/drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4'\n",
      "probs: None\n",
      "save_dir: 'runs/detect/predict'\n",
      "speed: {'preprocess': 8.98599624633789, 'inference': 401.5653133392334, 'postprocess': 9.197711944580078}\n",
      "------------------------------------------------------\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([2.])\n",
      "conf: tensor([0.8074])\n",
      "data: tensor([[1.7121e+03, 3.0267e+02, 1.7376e+03, 3.8563e+02, 8.0737e-01, 2.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1080, 1920)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[1724.8363,  344.1505,   25.4685,   82.9559]])\n",
      "xywhn: tensor([[0.8984, 0.3187, 0.0133, 0.0768]])\n",
      "xyxy: tensor([[1712.1021,  302.6725, 1737.5706,  385.6284]])\n",
      "xyxyn: tensor([[0.8917, 0.2803, 0.9050, 0.3571]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([2.])\n",
      "conf: tensor([0.7745])\n",
      "data: tensor([[585.6912, 325.6868, 608.2608, 401.0354,   0.7745,   2.0000]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1080, 1920)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[596.9760, 363.3611,  22.5696,  75.3486]])\n",
      "xywhn: tensor([[0.3109, 0.3364, 0.0118, 0.0698]])\n",
      "xyxy: tensor([[585.6912, 325.6868, 608.2608, 401.0354]])\n",
      "xyxyn: tensor([[0.3050, 0.3016, 0.3168, 0.3713]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([2.])\n",
      "conf: tensor([0.7691])\n",
      "data: tensor([[8.7186e+02, 3.1713e+02, 8.9599e+02, 3.9572e+02, 7.6914e-01, 2.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1080, 1920)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[883.9240, 356.4261,  24.1315,  78.5966]])\n",
      "xywhn: tensor([[0.4604, 0.3300, 0.0126, 0.0728]])\n",
      "xyxy: tensor([[871.8582, 317.1278, 895.9897, 395.7244]])\n",
      "xyxyn: tensor([[0.4541, 0.2936, 0.4667, 0.3664]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([2.])\n",
      "conf: tensor([0.7687])\n",
      "data: tensor([[474.8904, 525.2782, 507.7718, 619.0555,   0.7687,   2.0000]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1080, 1920)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[491.3311, 572.1669,  32.8813,  93.7773]])\n",
      "xywhn: tensor([[0.2559, 0.5298, 0.0171, 0.0868]])\n",
      "xyxy: tensor([[474.8904, 525.2782, 507.7718, 619.0555]])\n",
      "xyxyn: tensor([[0.2473, 0.4864, 0.2645, 0.5732]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([2.])\n",
      "conf: tensor([0.7496])\n",
      "data: tensor([[1.1933e+03, 3.4703e+02, 1.2153e+03, 4.2322e+02, 7.4957e-01, 2.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1080, 1920)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[1204.3411,  385.1256,   22.0033,   76.1898]])\n",
      "xywhn: tensor([[0.6273, 0.3566, 0.0115, 0.0705]])\n",
      "xyxy: tensor([[1193.3394,  347.0307, 1215.3427,  423.2205]])\n",
      "xyxyn: tensor([[0.6215, 0.3213, 0.6330, 0.3919]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([2.])\n",
      "conf: tensor([0.7414])\n",
      "data: tensor([[1.7078e+03, 4.2153e+02, 1.7357e+03, 5.1786e+02, 7.4138e-01, 2.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1080, 1920)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[1721.7880,  469.6974,   27.9155,   96.3289]])\n",
      "xywhn: tensor([[0.8968, 0.4349, 0.0145, 0.0892]])\n",
      "xyxy: tensor([[1707.8302,  421.5330, 1735.7457,  517.8618]])\n",
      "xyxyn: tensor([[0.8895, 0.3903, 0.9040, 0.4795]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([2.])\n",
      "conf: tensor([0.7098])\n",
      "data: tensor([[456.0515, 376.1784, 486.1437, 464.3858,   0.7098,   2.0000]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1080, 1920)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[471.0976, 420.2821,  30.0923,  88.2074]])\n",
      "xywhn: tensor([[0.2454, 0.3892, 0.0157, 0.0817]])\n",
      "xyxy: tensor([[456.0515, 376.1784, 486.1437, 464.3858]])\n",
      "xyxyn: tensor([[0.2375, 0.3483, 0.2532, 0.4300]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([2.])\n",
      "conf: tensor([0.7055])\n",
      "data: tensor([[9.6183e+02, 3.6777e+02, 1.0015e+03, 4.5171e+02, 7.0552e-01, 2.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1080, 1920)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[981.6651, 409.7423,  39.6603,  83.9414]])\n",
      "xywhn: tensor([[0.5113, 0.3794, 0.0207, 0.0777]])\n",
      "xyxy: tensor([[ 961.8350,  367.7716, 1001.4952,  451.7130]])\n",
      "xyxyn: tensor([[0.5010, 0.3405, 0.5216, 0.4183]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([2.])\n",
      "conf: tensor([0.6842])\n",
      "data: tensor([[9.8644e+02, 2.8029e+02, 1.0062e+03, 3.4752e+02, 6.8415e-01, 2.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1080, 1920)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[996.2975, 313.9058,  19.7130,  67.2361]])\n",
      "xywhn: tensor([[0.5189, 0.2907, 0.0103, 0.0623]])\n",
      "xyxy: tensor([[ 986.4410,  280.2878, 1006.1540,  347.5239]])\n",
      "xyxyn: tensor([[0.5138, 0.2595, 0.5240, 0.3218]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([2.])\n",
      "conf: tensor([0.6819])\n",
      "data: tensor([[7.6925e+02, 3.2333e+02, 8.0329e+02, 3.9736e+02, 6.8186e-01, 2.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1080, 1920)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[786.2694, 360.3441,  34.0455,  74.0243]])\n",
      "xywhn: tensor([[0.4095, 0.3337, 0.0177, 0.0685]])\n",
      "xyxy: tensor([[769.2466, 323.3320, 803.2922, 397.3563]])\n",
      "xyxyn: tensor([[0.4006, 0.2994, 0.4184, 0.3679]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([2.])\n",
      "conf: tensor([0.6708])\n",
      "data: tensor([[1.1020e+03, 2.2175e+02, 1.1222e+03, 2.7563e+02, 6.7079e-01, 2.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1080, 1920)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[1112.0972,  248.6893,   20.2072,   53.8743]])\n",
      "xywhn: tensor([[0.5792, 0.2303, 0.0105, 0.0499]])\n",
      "xyxy: tensor([[1101.9935,  221.7521, 1122.2007,  275.6264]])\n",
      "xyxyn: tensor([[0.5740, 0.2053, 0.5845, 0.2552]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([2.])\n",
      "conf: tensor([0.6691])\n",
      "data: tensor([[422.1373, 439.7846, 451.1716, 523.8344,   0.6691,   2.0000]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1080, 1920)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[436.6544, 481.8094,  29.0343,  84.0498]])\n",
      "xywhn: tensor([[0.2274, 0.4461, 0.0151, 0.0778]])\n",
      "xyxy: tensor([[422.1373, 439.7846, 451.1716, 523.8344]])\n",
      "xyxyn: tensor([[0.2199, 0.4072, 0.2350, 0.4850]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([2.])\n",
      "conf: tensor([0.6562])\n",
      "data: tensor([[1.1820e+03, 2.8751e+02, 1.2033e+03, 3.5660e+02, 6.5624e-01, 2.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1080, 1920)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[1192.6521,  322.0572,   21.2842,   69.0929]])\n",
      "xywhn: tensor([[0.6212, 0.2982, 0.0111, 0.0640]])\n",
      "xyxy: tensor([[1182.0100,  287.5107, 1203.2942,  356.6036]])\n",
      "xyxyn: tensor([[0.6156, 0.2662, 0.6267, 0.3302]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([1.])\n",
      "conf: tensor([0.6412])\n",
      "data: tensor([[211.8864, 318.7034, 231.5083, 393.4547,   0.6412,   1.0000]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1080, 1920)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[221.6973, 356.0790,  19.6219,  74.7514]])\n",
      "xywhn: tensor([[0.1155, 0.3297, 0.0102, 0.0692]])\n",
      "xyxy: tensor([[211.8864, 318.7034, 231.5083, 393.4547]])\n",
      "xyxyn: tensor([[0.1104, 0.2951, 0.1206, 0.3643]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([2.])\n",
      "conf: tensor([0.6404])\n",
      "data: tensor([[1.2237e+03, 2.3131e+02, 1.2441e+03, 2.9075e+02, 6.4035e-01, 2.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1080, 1920)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[1233.9189,  261.0285,   20.3613,   59.4466]])\n",
      "xywhn: tensor([[0.6427, 0.2417, 0.0106, 0.0550]])\n",
      "xyxy: tensor([[1223.7383,  231.3052, 1244.0996,  290.7518]])\n",
      "xyxyn: tensor([[0.6374, 0.2142, 0.6480, 0.2692]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([3.])\n",
      "conf: tensor([0.6356])\n",
      "data: tensor([[1.0726e+03, 3.3967e+02, 1.0989e+03, 4.1826e+02, 6.3565e-01, 3.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1080, 1920)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[1085.7852,  378.9645,   26.2958,   78.5918]])\n",
      "xywhn: tensor([[0.5655, 0.3509, 0.0137, 0.0728]])\n",
      "xyxy: tensor([[1072.6373,  339.6686, 1098.9331,  418.2604]])\n",
      "xyxyn: tensor([[0.5587, 0.3145, 0.5724, 0.3873]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([2.])\n",
      "conf: tensor([0.5972])\n",
      "data: tensor([[1.1312e+03, 2.2271e+02, 1.1456e+03, 2.6616e+02, 5.9719e-01, 2.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1080, 1920)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[1138.4336,  244.4339,   14.3705,   43.4559]])\n",
      "xywhn: tensor([[0.5929, 0.2263, 0.0075, 0.0402]])\n",
      "xyxy: tensor([[1131.2483,  222.7059, 1145.6188,  266.1618]])\n",
      "xyxyn: tensor([[0.5892, 0.2062, 0.5967, 0.2464]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([2.])\n",
      "conf: tensor([0.5708])\n",
      "data: tensor([[9.4502e+02, 2.3082e+02, 9.6625e+02, 2.8789e+02, 5.7078e-01, 2.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1080, 1920)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[955.6360, 259.3573,  21.2271,  57.0712]])\n",
      "xywhn: tensor([[0.4977, 0.2401, 0.0111, 0.0528]])\n",
      "xyxy: tensor([[945.0225, 230.8217, 966.2496, 287.8929]])\n",
      "xyxyn: tensor([[0.4922, 0.2137, 0.5033, 0.2666]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([2.])\n",
      "conf: tensor([0.5084])\n",
      "data: tensor([[4.8847e+02, 3.7130e+02, 5.2219e+02, 4.4915e+02, 5.0838e-01, 2.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1080, 1920)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[505.3296, 410.2249,  33.7246,  77.8407]])\n",
      "xywhn: tensor([[0.2632, 0.3798, 0.0176, 0.0721]])\n",
      "xyxy: tensor([[488.4673, 371.3046, 522.1919, 449.1453]])\n",
      "xyxyn: tensor([[0.2544, 0.3438, 0.2720, 0.4159]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([2.])\n",
      "conf: tensor([0.5041])\n",
      "data: tensor([[9.8822e+02, 2.2475e+02, 1.0050e+03, 2.8111e+02, 5.0414e-01, 2.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1080, 1920)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[996.6156, 252.9263,  16.7948,  56.3586]])\n",
      "xywhn: tensor([[0.5191, 0.2342, 0.0087, 0.0522]])\n",
      "xyxy: tensor([[ 988.2182,  224.7470, 1005.0130,  281.1056]])\n",
      "xyxyn: tensor([[0.5147, 0.2081, 0.5234, 0.2603]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([2.])\n",
      "conf: tensor([0.4821])\n",
      "data: tensor([[1.2058e+03, 2.7813e+02, 1.2260e+03, 3.4880e+02, 4.8208e-01, 2.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1080, 1920)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[1215.8833,  313.4639,   20.1423,   70.6757]])\n",
      "xywhn: tensor([[0.6333, 0.2902, 0.0105, 0.0654]])\n",
      "xyxy: tensor([[1205.8121,  278.1261, 1225.9545,  348.8017]])\n",
      "xyxyn: tensor([[0.6280, 0.2575, 0.6385, 0.3230]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([2.])\n",
      "conf: tensor([0.4467])\n",
      "data: tensor([[9.7822e+02, 3.6709e+02, 1.0025e+03, 4.4757e+02, 4.4671e-01, 2.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1080, 1920)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[990.3719, 407.3327,  24.3043,  80.4809]])\n",
      "xywhn: tensor([[0.5158, 0.3772, 0.0127, 0.0745]])\n",
      "xyxy: tensor([[ 978.2197,  367.0922, 1002.5240,  447.5731]])\n",
      "xyxyn: tensor([[0.5095, 0.3399, 0.5221, 0.4144]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([2.])\n",
      "conf: tensor([0.3801])\n",
      "data: tensor([[1.0717e+03, 3.3899e+02, 1.0983e+03, 4.1924e+02, 3.8013e-01, 2.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1080, 1920)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[1084.9668,  379.1172,   26.5726,   80.2507]])\n",
      "xywhn: tensor([[0.5651, 0.3510, 0.0138, 0.0743]])\n",
      "xyxy: tensor([[1071.6804,  338.9919, 1098.2531,  419.2426]])\n",
      "xyxyn: tensor([[0.5582, 0.3139, 0.5720, 0.3882]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([2.])\n",
      "conf: tensor([0.3730])\n",
      "data: tensor([[4.8622e+02, 3.6928e+02, 5.1346e+02, 4.5140e+02, 3.7297e-01, 2.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1080, 1920)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[499.8376, 410.3413,  27.2448,  82.1237]])\n",
      "xywhn: tensor([[0.2603, 0.3799, 0.0142, 0.0760]])\n",
      "xyxy: tensor([[486.2151, 369.2794, 513.4600, 451.4031]])\n",
      "xyxyn: tensor([[0.2532, 0.3419, 0.2674, 0.4180]])\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([2.])\n",
      "conf: tensor([0.2755])\n",
      "data: tensor([[1.2090e+03, 2.5501e+02, 1.2250e+03, 3.0879e+02, 2.7546e-01, 2.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1080, 1920)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[1216.9865,  281.8995,   15.9993,   53.7725]])\n",
      "xywhn: tensor([[0.6338, 0.2610, 0.0083, 0.0498]])\n",
      "xyxy: tensor([[1208.9868,  255.0132, 1224.9861,  308.7857]])\n",
      "xyxyn: tensor([[0.6297, 0.2361, 0.6380, 0.2859]])\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# model = YOLO('runs/detect/train/weights/best.pt')\n",
    "\n",
    "model = YOLO('runs/detect/train5/weights/best.pt')\n",
    "\n",
    "# results = model.predict('drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4', save=True)\n",
    "results = model.predict('drive/MyDrive/Colab Notebooks/YOLO/input_video/challenge-1003_2.mp4', save=True)\n",
    "\n",
    "print(results[0])\n",
    "\n",
    "print('------------------------------------------------------')\n",
    "\n",
    "for box in results[0].boxes:\n",
    "  print(box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HG1Jwf7cNfbP"
   },
   "source": [
    "YOLO training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7_8lsMEVTVAE"
   },
   "source": [
    "GET DATASET(tải qua roboflow api và lưu trong folder football-players-detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 11627,
     "status": "ok",
     "timestamp": 1736040165183,
     "user": {
      "displayName": "Công Thành Nguyễn",
      "userId": "18021098019939229396"
     },
     "user_tz": -420
    },
    "id": "IvXA5L4tNiIb",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "0c701d6e-6e8c-48b3-8161-ba86cbd84f71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in football-players-detection-12 to yolov8:: 100%|██████████| 65763/65763 [00:01<00:00, 54009.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to football-players-detection-12 in yolov8:: 100%|██████████| 756/756 [00:00<00:00, 2343.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"API_KEY\")\n",
    "project = rf.workspace(\"roboflow-jvuqo\").project(\"football-players-detection-3zvbc\")\n",
    "version = project.version(12)\n",
    "dataset = version.download(\"yolov8\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1736040165183,
     "user": {
      "displayName": "Công Thành Nguyễn",
      "userId": "18021098019939229396"
     },
     "user_tz": -420
    },
    "id": "yYFOBm7dgI7h",
    "outputId": "ef47f3a1-5445-4bab-a84e-ab79f5f225ce"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/football-players-detection-12'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CUIx5kzOhSUe"
   },
   "source": [
    "Di chuyển dataset vừa tạo vào thư mục trong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vcA_8c0XgxlE"
   },
   "outputs": [],
   "source": [
    "# import shutil\n",
    "\n",
    "# shutil.move('football-players-detection-12/train',\n",
    "#             'football-players-detection-12/football-players-detection-12/train')\n",
    "\n",
    "# shutil.move('football-players-detection-12/test',\n",
    "#             'football-players-detection-12/football-players-detection-12/test')\n",
    "\n",
    "# shutil.move('football-players-detection-12/valid',\n",
    "#             'football-players-detection-12/football-players-detection-12/valid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UyjUFvDthXMv"
   },
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1736040165184,
     "user": {
      "displayName": "Công Thành Nguyễn",
      "userId": "18021098019939229396"
     },
     "user_tz": -420
    },
    "id": "EkigrUmwjyD7",
    "outputId": "7db1e995-8bbc-44d4-fcae-6cd92012b847"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/football-players-detection-12'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hjG_alZ-5HAb"
   },
   "source": [
    "Train dataset với:\n",
    "\n",
    "*   nhiệm vụ(task) là detect hay còn hiểu là phát hiện\n",
    "*   chế độ(mode) là train huấn luyện trên bộ dữ liệu mới\n",
    "*   mô hình(model) là yolov8n.pt mô hình YOLO được chỉ định sử dụng\n",
    "*   dữ liệu(data) đường dẫn đến tập dữ liệu là bộ dữ liệu được lấy từ roboflow\n",
    "*   số lần duyệt qua toàn bộ tập dữ liệu mô hình(echo): số lượng echo để huấn luyện mô hình(hiện tại đang để là 10)\n",
    "*   kích thước đầu vào của hình ảnh(imgsz) kích cỡ 640x640\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16016640,
     "status": "ok",
     "timestamp": 1736056314166,
     "user": {
      "displayName": "Công Thành Nguyễn",
      "userId": "18021098019939229396"
     },
     "user_tz": -420
    },
    "id": "GzBhkyLOhWxD",
    "outputId": "20cfd610-6a73-47b4-a900-f84bbd015ad3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11s.pt to 'yolo11s.pt'...\n",
      "100% 18.4M/18.4M [00:00<00:00, 86.5MB/s]\n",
      "Ultralytics 8.3.57 🚀 Python-3.10.12 torch-2.5.1+cu121 CPU (Intel Xeon 2.20GHz)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11s.pt, data=/content/football-players-detection-12/data.yaml, epochs=20, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train2\n",
      "Overriding model.yaml nc=80 with nc=4\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
      "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    443776  ultralytics.nn.modules.block.C3k2            [768, 256, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    127680  ultralytics.nn.modules.block.C3k2            [512, 128, 1, False]          \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    345472  ultralytics.nn.modules.block.C3k2            [384, 256, 1, False]          \n",
      " 20                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
      " 23        [16, 19, 22]  1    820956  ultralytics.nn.modules.head.Detect           [4, [128, 256, 512]]          \n",
      "YOLO11s summary: 319 layers, 9,429,340 parameters, 9,429,324 gradients, 21.6 GFLOPs\n",
      "\n",
      "Transferred 493/499 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train2', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/football-players-detection-12/train/labels.cache... 298 images, 0 backgrounds, 0 corrupt: 100% 298/298 [00:00<?, ?it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.24 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/football-players-detection-12/valid/labels.cache... 49 images, 0 backgrounds, 0 corrupt: 100% 49/49 [00:00<?, ?it/s]\n",
      "Plotting labels to runs/detect/train2/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train2\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/20         0G      1.327      2.216     0.8849        352        640: 100% 19/19 [12:46<00:00, 40.36s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0% 0/2 [00:00<?, ?it/s]WARNING ⚠️ NMS time limit 3.600s exceeded\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  50% 1/2 [00:31<00:31, 31.80s/it]WARNING ⚠️ NMS time limit 2.850s exceeded\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:49<00:00, 24.50s/it]\n",
      "                   all         49       1174       0.73      0.172      0.178      0.103\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/20         0G       1.26     0.9903     0.8478        296        640: 100% 19/19 [12:45<00:00, 40.27s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:46<00:00, 23.48s/it]\n",
      "                   all         49       1174      0.318      0.443      0.383      0.208\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/20         0G      1.194     0.8441     0.8379        387        640: 100% 19/19 [12:35<00:00, 39.74s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:44<00:00, 22.35s/it]\n",
      "                   all         49       1174      0.233      0.424      0.205      0.122\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/20         0G      1.138     0.7351     0.8387        299        640: 100% 19/19 [12:38<00:00, 39.94s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:40<00:00, 20.36s/it]\n",
      "                   all         49       1174        0.6      0.511      0.552       0.33\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/20         0G      1.246     0.7563     0.8431        240        640: 100% 19/19 [12:40<00:00, 40.05s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:42<00:00, 21.04s/it]\n",
      "                   all         49       1174      0.739      0.619      0.687      0.417\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/20         0G       1.18     0.7039     0.8396        199        640: 100% 19/19 [12:40<00:00, 40.01s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:43<00:00, 21.90s/it]\n",
      "                   all         49       1174      0.652      0.566      0.634      0.364\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/20         0G      1.128     0.6693     0.8325        273        640: 100% 19/19 [12:44<00:00, 40.21s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:42<00:00, 21.38s/it]\n",
      "                   all         49       1174      0.737      0.668      0.713       0.42\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/20         0G       1.12     0.6579     0.8323        306        640: 100% 19/19 [12:38<00:00, 39.92s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:43<00:00, 21.96s/it]\n",
      "                   all         49       1174      0.693      0.663      0.707      0.447\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/20         0G      1.062     0.6054     0.8251        318        640: 100% 19/19 [12:41<00:00, 40.06s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:43<00:00, 21.59s/it]\n",
      "                   all         49       1174       0.83      0.666      0.735      0.449\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/20         0G      1.067     0.6082     0.8211        204        640: 100% 19/19 [12:41<00:00, 40.06s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:43<00:00, 21.62s/it]\n",
      "                   all         49       1174      0.793      0.686      0.754      0.496\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      11/20         0G     0.9407     0.5526     0.8163        242        640: 100% 19/19 [12:15<00:00, 38.72s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:42<00:00, 21.43s/it]\n",
      "                   all         49       1174      0.797       0.71      0.764      0.498\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      12/20         0G     0.9498     0.5471     0.8174        237        640: 100% 19/19 [12:28<00:00, 39.40s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:42<00:00, 21.31s/it]\n",
      "                   all         49       1174      0.836      0.715      0.756      0.488\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      13/20         0G     0.9603     0.5421      0.818        225        640: 100% 19/19 [12:21<00:00, 39.05s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:44<00:00, 22.21s/it]\n",
      "                   all         49       1174      0.808        0.7      0.754      0.481\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      14/20         0G     0.9076     0.5235     0.8168        221        640: 100% 19/19 [12:21<00:00, 39.04s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:43<00:00, 21.52s/it]\n",
      "                   all         49       1174      0.836      0.727      0.778      0.509\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      15/20         0G     0.8807     0.5012     0.8143        229        640: 100% 19/19 [12:25<00:00, 39.25s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:42<00:00, 21.23s/it]\n",
      "                   all         49       1174      0.895      0.714      0.782      0.526\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      16/20         0G     0.8634     0.4926     0.8109        241        640: 100% 19/19 [12:18<00:00, 38.89s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:42<00:00, 21.38s/it]\n",
      "                   all         49       1174      0.923      0.739      0.801      0.532\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      17/20         0G     0.8689     0.4817     0.8113        236        640: 100% 19/19 [12:17<00:00, 38.80s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:43<00:00, 21.60s/it]\n",
      "                   all         49       1174      0.942      0.733      0.807      0.537\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      18/20         0G     0.8514     0.4698     0.8094        231        640: 100% 19/19 [12:24<00:00, 39.18s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:43<00:00, 21.98s/it]\n",
      "                   all         49       1174      0.898      0.756      0.799      0.543\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      19/20         0G     0.8443     0.4671     0.8097        225        640: 100% 19/19 [12:24<00:00, 39.18s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:43<00:00, 21.93s/it]\n",
      "                   all         49       1174      0.946      0.725      0.805      0.544\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      20/20         0G     0.8228     0.4556     0.8055        226        640: 100% 19/19 [12:23<00:00, 39.16s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:41<00:00, 20.84s/it]\n",
      "                   all         49       1174       0.93      0.739      0.804      0.551\n",
      "\n",
      "20 epochs completed in 4.428 hours.\n",
      "Optimizer stripped from runs/detect/train2/weights/last.pt, 19.2MB\n",
      "Optimizer stripped from runs/detect/train2/weights/best.pt, 19.2MB\n",
      "\n",
      "Validating runs/detect/train2/weights/best.pt...\n",
      "Ultralytics 8.3.57 🚀 Python-3.10.12 torch-2.5.1+cu121 CPU (Intel Xeon 2.20GHz)\n",
      "YOLO11s summary (fused): 238 layers, 9,414,348 parameters, 0 gradients, 21.3 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:39<00:00, 19.70s/it]\n",
      "                   all         49       1174       0.93      0.739      0.804      0.551\n",
      "                  ball         45         45      0.983      0.289      0.371      0.149\n",
      "            goalkeeper         38         39       0.97      0.841      0.945      0.682\n",
      "                player         49        973      0.938      0.954      0.984      0.775\n",
      "               referee         49        117      0.828      0.872      0.915      0.597\n",
      "Speed: 3.3ms preprocess, 768.8ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train2\u001b[0m\n",
      "💡 Learn more at https://docs.ultralytics.com/modes/train\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=train model=yolo11s.pt data={dataset.location}/data.yaml epochs=20 imgsz=640"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cb74tMvu7H8N"
   },
   "source": [
    "Có vẻ như mỗi lần chạy echo sẽ tốn x phút\n",
    "\n",
    "- x sẽ phụ thuộc vào từng mô hình\n",
    "- với mô hình v8n(mô hình cỡ siêu nhỏ nano) thì mất 5 phút\n",
    "- với mô hình 11s(mô hình cỡ nhỏ small) thì mất 13 phút"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1736056315977,
     "user": {
      "displayName": "Công Thành Nguyễn",
      "userId": "18021098019939229396"
     },
     "user_tz": -420
    },
    "id": "lNJnEuyVvbd_",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!cp runs/detect/train2/weights/best.pt drive/MyDrive/Colab\\ Notebooks/YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "executionInfo": {
     "elapsed": 317,
     "status": "ok",
     "timestamp": 1736056346477,
     "user": {
      "displayName": "Công Thành Nguyễn",
      "userId": "18021098019939229396"
     },
     "user_tz": -420
    },
    "id": "kZSROkTWxhiN",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!cp runs/detect/train2/weights/last.pt drive/MyDrive/Colab\\ Notebooks/YOLO"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNQCTAqP8hJPSVpXRt8ohui",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
